import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import os
import json
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Dual-AI Hub", layout="wide")
st.title("ğŸ¤– Dual-AI Insight Hub")

# --- 1. API í‚¤ ì„¤ì • ---
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    gpt_api_key = st.secrets["GPT_API_KEY"]
except FileNotFoundError:
    st.error("ğŸš¨ Secrets ì„¤ì •ì´ ì•ˆ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Streamlit Settingsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# --- 2. ëª¨ë¸ ì´ˆê¸°í™” ---
genai.configure(api_key=gemini_api_key)
gpt_client = OpenAI(api_key=gpt_api_key)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "g_resp" not in st.session_state: st.session_state.g_resp = ""
if "o_resp" not in st.session_state: st.session_state.o_resp = ""
if "g_an" not in st.session_state: st.session_state.g_an = ""
if "o_an" not in st.session_state: st.session_state.o_an = ""
if "final_con" not in st.session_state: st.session_state.final_con = "" 
if "user_q" not in st.session_state: st.session_state.user_q = "" # ì§ˆë¬¸ ê¸°ì–µìš©

# --- 3. [í•µì‹¬] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ ì§„ë‹¨ ë° ì„ íƒ ---
# ì´ í•¨ìˆ˜ê°€ 404 ì—ëŸ¬ë¥¼ ë§‰ì•„ì£¼ëŠ” í•µì‹¬ì…ë‹ˆë‹¤!
def get_available_gemini_model():
    try:
        # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì„œë²„ì— ë¬¼ì–´ë´…ë‹ˆë‹¤.
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # 2. ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìˆœì„œëŒ€ë¡œ ì°¾ì•„ë´…ë‹ˆë‹¤. (ìµœì‹  Flash ìš°ì„ )
        preferred_order = ['models/gemini-1.5-flash', 'models/gemini-pro', 'models/gemini-1.0-pro']
        
        for model in preferred_order:
            if model in available_models:
                return model
        
        # 3. ì—†ìœ¼ë©´ ëª©ë¡ì— ìˆëŠ” ê±° ì•„ë¬´ê±°ë‚˜ë¼ë„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if available_models:
            return available_models[0]
            
        return None
    except Exception:
        return None

# ëª¨ë¸ ê²°ì •
valid_model_name = get_available_gemini_model()
if not valid_model_name:
    # ì •ë§ ëª» ì°¾ê² ìœ¼ë©´ ê¸°ë³¸ê°’ (í•˜ì§€ë§Œ ìœ„ í•¨ìˆ˜ì—ì„œ ëŒ€ë¶€ë¶„ ì°¾ì•„ëƒ…ë‹ˆë‹¤)
    valid_model_name = "gemini-pro"

# --- íƒ­ êµ¬ì„± ---
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ 1. ë™ì‹œ ì§ˆë¬¸", "ğŸ“Š 2. êµì°¨ ë¶„ì„", "ğŸ† 3. ìµœì¢… ê²°ë¡ "])

# --- íƒ­ 1: ì§ˆë¬¸í•˜ê¸° ---
with tab1:
    st.info("ğŸ‘‹ ì‚¬ìš©ìë‹˜ ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    
    if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.user_q = user_input
        st.write(f"**ğŸ™‹â€â™‚ï¸ ì§ˆë¬¸:** {user_input}")
        
        with st.spinner("ë‹¤ì˜¨ê³¼ ë£¨ê°€ ë‹µë³€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # 1. ë‹¤ì˜¨ (Gemini) - ìë™ ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©
            try:
                # ëª¨ë¸ ì´ë¦„ì—ì„œ 'models/'ë¥¼ ë¹¼ê³  í˜¸ì¶œí•´ì•¼ í•  ë•Œë„ ìˆì–´ì„œ ì²˜ë¦¬
                safe_model_name = valid_model_name.replace('models/', '')
                model = genai.GenerativeModel(safe_model_name) 
                response = model.generate_content(user_input)
                st.session_state.g_resp = response.text
            except Exception as e:
                st.session_state.g_resp = f"âŒ ë‹¤ì˜¨ ì—ëŸ¬ (ì‹œë„í•œ ëª¨ë¸: {valid_model_name}):\n{str(e)}"

            # 2. ë£¨ (GPT)
            try:
                response = gpt_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": user_input}]
                )
                st.session_state.o_resp = response.choices[0].message.content
            except Exception as e:
                st.session_state.o_resp = f"âŒ ë£¨ ì—ëŸ¬: {str(e)}"

        # ê²°ê³¼ ì¶œë ¥
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"ğŸ’ ë‹¤ì˜¨ (Gemini)")
            st.write(st.session_state.g_resp)
        with col2:
            st.success("ğŸ§  ë£¨ (Chat GPT)")
            st.write(st.session_state.o_resp)
            
    # ì´ì „ ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
    elif st.session_state.g_resp:
         st.write(f"**ğŸ™‹â€â™‚ï¸ ì§ˆë¬¸:** {st.session_state.get('user_q', '')}")
         col1, col2 = st.columns(2)
         with col1:
             st.info(f"ğŸ’ ë‹¤ì˜¨ (Gemini)")
             st.write(st.session_state.g_resp)
         with col2:
             st.success("ğŸ§  ë£¨ (Chat GPT)")
             st.write(st.session_state.o_resp)

# --- íƒ­ 2: êµì°¨ ë¶„ì„ ---
with tab2:
    if st.button("êµì°¨ ë¶„ì„ ì‹œì‘"):
        if not st.session_state.g_resp or not st.session_state.o_resp:
            st.warning("ë¨¼ì € 1ë‹¨ê³„ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ì„œë¡œì˜ ë…¼ë¦¬ë¥¼ ê²€ì¦í•˜ëŠ” ì¤‘..."):
                # ë‹¤ì˜¨ -> ë£¨ ë¶„ì„ (ì•ˆì „ ì„¤ì • ì ìš©)
                try:
                    safe_model_name = valid_model_name.replace('models/', '')
                    model = genai.GenerativeModel(safe_model_name)
                    
                    # ë¹„íŒ í—ˆìš© ì„¤ì •
                    safety_settings = [
                        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
                    ]
                    
                    prompt = f"ë‹¤ìŒì€ 'ë£¨(GPT)'ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ë…¼ë¦¬ì  í—ˆì ì´ë‚˜ ë³´ì™„í•  ì ì„ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{st.session_state.o_resp}"
                    res = model.generate_content(prompt, safety_settings=safety_settings)
                    st.session_state.g_an = res.text
                except Exception as e:
                    st.session_state.g_an = f"ë¶„ì„ ì‹¤íŒ¨: {e}"

                # ë£¨ -> ë‹¤ì˜¨ ë¶„ì„
                try:
                    res = gpt_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role":"user","content":f"ë‹¤ìŒì€ 'ë‹¤ì˜¨(Gemini)'ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ì°½ì˜ì„±ê³¼ ê°ì„±ì ì¸ ì¸¡ë©´, ê·¸ë¦¬ê³  ë…¼ë¦¬ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”:\n{st.session_state.g_resp}"}]
                    )
                    st.session_state.o_an = res.choices[0].message.content
                except Exception as e:
                    st.session_state.o_an = f"ë¶„ì„ ì‹¤íŒ¨: {e}"
            
            c1, c2 = st.columns(2)
            with c1:
                st.info("ğŸ’ ë‹¤ì˜¨ì˜ ë¹„í‰")
                st.write(st.session_state.g_an)
            with c2:
                st.success("ğŸ§  ë£¨ì˜ í‰ê°€")
                st.write(st.session_state.o_an)
    
    # ë¶„ì„ ê²°ê³¼ ìœ ì§€
    elif st.session_state.g_an:
        c1, c2 = st.columns(2)
        with c1:
            st.info("ğŸ’ ë‹¤ì˜¨ì˜ ë¹„í‰")
            st.write(st.session_state.g_an)
        with c2:
            st.success("ğŸ§  ë£¨ì˜ í‰ê°€")
            st.write(st.session_state.o_an)

# --- íƒ­ 3: ìµœì¢… ê²°ë¡  ---
with tab3:
    st.subheader("ğŸ† ë£¨(GPT)ê°€ ë‚´ë¦¬ëŠ” ìµœì¢… íŒê²°")
    st.caption("ì§ˆë¬¸, ë‹µë³€, ìƒí˜¸ ë¹„íŒì„ ëª¨ë‘ ì¢…í•©í•˜ì—¬ ìµœì¢… ê²°ë¡ ì„ ë‚´ë¦½ë‹ˆë‹¤.")

    if st.button("ìµœì¢… ê²°ë¡  ë„ì¶œí•˜ê¸°"):
        if not st.session_state.g_an or not st.session_state.o_an:
            st.warning("ë¨¼ì € '2. êµì°¨ ë¶„ì„' íƒ­ì—ì„œ ë¶„ì„ì„ ì™„ë£Œí•´ì•¼ ê²°ë¡ ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            with st.spinner("ìµœì¢… ë³´ê³ ì„œ ì‘ì„± ì¤‘..."):
                try:
                    final_prompt = f"""
                    ë„ˆëŠ” ìµœì¢… ì˜ì‚¬ê²°ì •ê¶Œìë‹¤. ì•„ë˜ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ëª…ì¾Œí•œ ê²°ë¡ ì„ ë‚´ë ¤ë¼.

                    [ì§ˆë¬¸] {st.session_state.user_q}
                    [ë‹¤ì˜¨ ë‹µë³€] {st.session_state.g_resp}
                    [ë£¨ ë‹µë³€] {st.session_state.o_resp}
                    [ë‹¤ì˜¨ ë¹„í‰] {st.session_state.g_an}
                    [ë£¨ ë¹„í‰] {st.session_state.o_an}

                    ì‘ì„± ê°€ì´ë“œ:
                    1. í•µì‹¬ ìŸì  ìš”ì•½
                    2. ì–‘ì¸¡ ì˜ê²¬ì˜ ì¥ë‹¨ì  ë¹„êµ
                    3. ìµœì¢… ì¡°ì–¸ (êµ¬ì²´ì ìœ¼ë¡œ)
                    """

                    res = gpt_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": final_prompt}]
                    )
                    st.session_state.final_con = res.choices[0].message.content
                
                except Exception as e:
                    st.error(f"ê²°ë¡  ë„ì¶œ ì‹¤íŒ¨: {e}")

    if st.session_state.final_con:
        st.markdown("---")
        st.markdown(st.session_state.final_con)
