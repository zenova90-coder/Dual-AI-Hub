import streamlit as st
import google.generativeai as genai
from openai import OpenAI
from datetime import datetime
import json
import os
import time

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Dual-AI Hub (Pro)", layout="wide")
st.title("ğŸ¤– Dual-AI Insight Hub")

# --- 2. API í‚¤ ì„¤ì • ---
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    gpt_api_key = st.secrets["GPT_API_KEY"]
except KeyError:
    st.error("ğŸš¨ API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

genai.configure(api_key=gemini_api_key)
gpt_client = OpenAI(api_key=gpt_api_key)

# --- 3. ëª¨ë¸ ìë™ íƒìƒ‰ ---
def get_best_available_model():
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        priority_keywords = ['1.5-flash', '1.5-pro', 'gemini-pro']
        for keyword in priority_keywords:
            for m in models:
                if keyword in m: return m
        return models[0] if models else "models/gemini-pro"
    except: return "models/gemini-pro"

TARGET_MODEL = get_best_available_model()

# --- 4. ë°ì´í„° ê´€ë¦¬ (íŒŒì¼ ì €ì¥) ---
DB_FILE = "chat_db.json"

def load_data():
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: return [{"title": "ìƒˆ ëŒ€í™”", "history": []}]
    return [{"title": "ìƒˆ ëŒ€í™”", "history": []}]

def save_data(sessions):
    with open(DB_FILE, "w", encoding="utf-8") as f:
        json.dump(sessions, f, ensure_ascii=False, indent=4)

# --- 5. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ---
if "sessions" not in st.session_state:
    st.session_state.sessions = load_data()
    st.session_state.active_index = 0

if "active_index" not in st.session_state:
    st.session_state.active_index = 0

def get_active_session():
    if st.session_state.active_index >= len(st.session_state.sessions):
        st.session_state.active_index = 0
    return st.session_state.sessions[st.session_state.active_index]

# --- 6. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("ğŸ—‚ï¸ ëŒ€í™” ê¸°ë¡")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("â• ìƒˆ ëŒ€í™”", use_container_width=True):
            new_session = {"title": "ìƒˆ ëŒ€í™”", "history": []}
            st.session_state.sessions.insert(0, new_session)
            st.session_state.active_index = 0
            save_data(st.session_state.sessions)
            st.rerun()
    with col2:
        if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", use_container_width=True):
            if os.path.exists(DB_FILE): os.remove(DB_FILE)
            st.session_state.sessions = [{"title": "ìƒˆ ëŒ€í™”", "history": []}]
            st.session_state.active_index = 0
            st.rerun()

    st.divider()
    for i, session in enumerate(st.session_state.sessions):
        label = session["title"]
        if len(label) > 12: label = label[:12] + "..."
        if i == st.session_state.active_index:
            st.button(f"ğŸ“‚ {label}", key=f"s_{i}", use_container_width=True, disabled=True)
        else:
            if st.button(f"ğŸ“„ {label}", key=f"s_{i}", use_container_width=True):
                st.session_state.active_index = i
                st.rerun()

# --- 7. ë©”ì¸ ë¡œì§ ---
active_session = get_active_session()
chat_history = active_session["history"]

user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")

if user_input:
    if len(chat_history) == 0:
        active_session["title"] = user_input
        save_data(st.session_state.sessions)

    with st.status("ğŸš€ AI ì‹¬ì¸µ ë¶„ì„ ì§„í–‰ ì¤‘...", expanded=True) as status:
        turn_data = {"q": user_input, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M")}

        try:
            # 1. ë‹µë³€
            st.write("1ï¸âƒ£ ë‹¤ì˜¨ & ë£¨ ë‹µë³€ ì‘ì„± ì¤‘...")
            model = genai.GenerativeModel(TARGET_MODEL)
            turn_data["g_resp"] = model.generate_content(user_input).text
            
            o_res = gpt_client.chat.completions.create(
                model="gpt-4o", messages=[{"role": "user", "content": user_input}]
            )
            turn_data["o_resp"] = o_res.choices[0].message.content

            # 2. ë¶„ì„
            st.write("2ï¸âƒ£ êµì°¨ ë¹„íŒ ë° ê²€ì¦ ì¤‘...")
            turn_data["g_an"] = model.generate_content(f"ë‹¤ìŒì€ Chat GPTì˜ ë‹µë³€ì…ë‹ˆë‹¤. ë…¼ë¦¬ì  í—ˆì ì´ë‚˜ ì‚¬ì‹¤ ê´€ê³„ ì˜¤ë¥˜ë¥¼ ë‚ ì¹´ë¡­ê²Œ ë¹„íŒí•´ì£¼ì„¸ìš”:\n{turn_data['o_resp']}").text
            
            o_an = gpt_client.chat.completions.create(
                model="gpt-4o", messages=[{"role": "user", "content": f"ë‹¤ìŒì€ Geminiì˜ ë‹µë³€ì…ë‹ˆë‹¤. ì°½ì˜ì„±, ë…¼ë¦¬, ì‹¤í˜„ ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ê³  ë¶€ì¡±í•œ ì ì„ ì§€ì í•´ì£¼ì„¸ìš”:\n{turn_data['g_resp']}"}]
            )
            turn_data["o_an"] = o_an.choices[0].message.content

            # 3. ê²°ë¡  (ê°•í™”ëœ í”„ë¡¬í”„íŠ¸)
            st.write("3ï¸âƒ£ ìµœì¢… ê²°ë¡  ë„ì¶œ ì¤‘...")
            final_prompt = f"""
            ë„ˆëŠ” ì´ í† ë¡ ì˜ 'ìµœì¢… ì˜ì‚¬ê²°ì •ê¶Œì'ë‹¤. ì•„ë˜ì˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì™„ë²½í•œ í•´ë‹µì„ ì‘ì„±í•˜ë¼.

            [ì‚¬ìš©ì ì§ˆë¬¸]: {user_input}
            
            [AI 1: Gemini ì˜ê²¬]: {turn_data['g_resp']}
            [AI 2: GPT ì˜ê²¬]: {turn_data['o_resp']}
            
            [Geminiì˜ ë¹„í‰ (GPT ì§€ì )]: {turn_data['g_an']}
            [GPTì˜ ë¹„í‰ (Gemini ì§€ì )]: {turn_data['o_an']}
            
            [ì‘ì„± ì§€ì¹¨]
            1. ë‹¨ìˆœíˆ ë‘ ì˜ê²¬ì„ ìš”ì•½í•˜ì§€ ë§ ê²ƒ.
            2. **'ë¹„í‰' íƒ­ì—ì„œ ì§€ì ëœ ì˜¤ë¥˜ë‚˜ ë¬¸ì œì ì€ ë°˜ë“œì‹œ ìµœì¢… ë‹µë³€ì— 'ìˆ˜ì • ë° ë°˜ì˜'í•  ê²ƒ.** (ì˜ˆ: Geminiê°€ GPTì˜ ë…¼ë¦¬ ì˜¤ë¥˜ë¥¼ ì§€ì í–ˆë‹¤ë©´, ê·¸ ë¶€ë¶„ì„ ê³ ì³ì„œ ë‹µë³€í•  ê²ƒ)
            3. ë‘ AIì˜ ì¥ì ë§Œì„ ê²°í•©í•˜ì—¬, ì‚¬ìš©ìê°€ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°€ì¥ êµ¬ì²´ì ì´ê³  ì˜¬ë°”ë¥¸ ê²°ë¡ ì„ ì œì‹œí•  ê²ƒ.
            """
            
            final_res = gpt_client.chat.completions.create(
                model="gpt-4o", messages=[{"role": "user", "content": final_prompt}]
            )
            turn_data["final_con"] = final_res.choices[0].message.content

            # ì €ì¥ ë° ì™„ë£Œ
            active_session["history"].append(turn_data)
            save_data(st.session_state.sessions)
            
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
            time.sleep(1)
            st.rerun()

        except Exception as e:
            st.error(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

# --- 8. í™”ë©´ ì¶œë ¥ ---
if chat_history:
    st.caption(f"ğŸ•’ í˜„ì¬ ëŒ€í™”: {len(chat_history)}ê°œì˜ ë¶„ì„ ê¸°ë¡")
    total_count = len(chat_history)
    
    for i, chat in enumerate(reversed(chat_history)):
        idx = total_count - i
        st.markdown(f"### Q{idx}. {chat['q']}")
        
        tab1, tab2, tab3 = st.tabs(["ğŸ’¬ ì˜ê²¬ ëŒ€ë¦½", "âš”ï¸ êµì°¨ ê²€ì¦", "ğŸ† ìµœì¢… ê²°ë¡ "])
        
        with tab1:
            c1, c2 = st.columns(2)
            with c1: 
                st.info("ğŸ’ ë‹¤ì˜¨ (Gemini)")
                st.write(chat['g_resp'])
            with c2: 
                st.success("ğŸ§  ë£¨ (Chat GPT)")
                st.write(chat['o_resp'])
        with tab2:
            c1, c2 = st.columns(2)
            with c1: 
                st.info("ë¹„í‰")
                st.write(chat['g_an'])
            with c2: 
                st.success("í‰ê°€")
                st.write(chat['o_an'])
        with tab3:
            st.markdown(chat['final_con'])
        st.divider()
