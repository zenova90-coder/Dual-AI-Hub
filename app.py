import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import json
import os
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Dual-AI Hub Pro", layout="wide")

# --- [ê´€ë¦¬ì ê¸°ëŠ¥] ì‚¬ìš©ì ì¥ë¶€ ë° ê¸°ë¡ ê´€ë¦¬ ---
USER_DB_FILE = "users.json"
HISTORY_FILE = "chat_history.json"

def load_users():
    if not os.path.exists(USER_DB_FILE):
        default_db = {
            "minju": {"pw": "1234", "credits": 9999, "name": "ì–‘ë¯¼ì£¼(Admin)"},
            "guest": {"pw": "0000", "credits": 3, "name": "ì²´í—˜íŒì†ë‹˜"} 
        }
        with open(USER_DB_FILE, "w", encoding="utf-8") as f:
            json.dump(default_db, f)
        return default_db
    with open(USER_DB_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

def deduct_credit(username):
    users = load_users()
    if users[username]["credits"] > 0:
        users[username]["credits"] -= 1
        with open(USER_DB_FILE, "w", encoding="utf-8") as f:
            json.dump(users, f, indent=4)
        return True
    return False

# íˆìŠ¤í† ë¦¬: ì´ë²ˆì—ëŠ” 'ì„¸ì…˜ ì „ì²´(ì—¬ëŸ¬ ì§ˆë¬¸)'ë¥¼ ì €ì¥í•˜ëŠ” êµ¬ì¡°ë¡œ ë³€ê²½
def save_session_history(username, session_data):
    if not session_data: return
    
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            history = json.load(f)
    else:
        history = []
    
    # ì €ì¥í•  ë°ì´í„°: ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
    record = {
        "user": username,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "title": session_data[0]['q'][:15] + "...", # ì²« ì§ˆë¬¸ ìš”ì•½
        "dialogue": session_data # ëŒ€í™” ì „ì²´ ë¦¬ìŠ¤íŠ¸
    }
    
    history.insert(0, record)
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=4)

def load_history_list(username):
    if not os.path.exists(HISTORY_FILE): return []
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            all_history = json.load(f)
            return [h for h in all_history if h.get("user") == username]
    except: return []

# --- API í‚¤ ì„¤ì • ---
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    gpt_api_key = st.secrets["GPT_API_KEY"]
    genai.configure(api_key=gemini_api_key)
    gpt_client = OpenAI(api_key=gpt_api_key)
except:
    st.error("API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

# --- ëª¨ë¸ ì„¤ì • ---
def get_gemini_model():
    return 'gemini-pro' # ì•ˆì •ì„± ìš°ì„ 

valid_model_name = get_gemini_model()

# ==========================================
# ğŸ” ë¡œê·¸ì¸ í™”ë©´
# ==========================================
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
    st.session_state.username = ""

if not st.session_state.logged_in:
    st.title("ğŸ”’ Dual-AI Hub ë¡œê·¸ì¸")
    col1, col2 = st.columns([1, 2])
    with col1:
        input_id = st.text_input("ì•„ì´ë””")
        input_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
        if st.button("ë¡œê·¸ì¸"):
            users = load_users()
            if input_id in users and users[input_id]["pw"] == input_pw:
                st.session_state.logged_in = True
                st.session_state.username = input_id
                st.rerun()
            else:
                st.error("ë¡œê·¸ì¸ ì‹¤íŒ¨")
    st.stop()

# ==========================================
# ğŸ  ë©”ì¸ ì„œë¹„ìŠ¤ í™”ë©´
# ==========================================
user_db = load_users()
current_user = st.session_state.username
current_credits = user_db[current_user]["credits"]

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title(f"ğŸ‘¤ {user_db[current_user]['name']}")
st.sidebar.caption(f"ì”ì—¬ ì´ìš©ê¶Œ: {current_credits}íšŒ")
st.sidebar.progress(min(current_credits / 10, 1.0))

if current_credits <= 0:
    st.error("ì´ìš©ê¶Œì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    st.stop()

st.title("ğŸ¤– Dual-AI Insight Hub")

# --- ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (ëŒ€í™” ë¦¬ìŠ¤íŠ¸) ---
# current_chat_log: ì§ˆë¬¸ê³¼ ë‹µë³€ë“¤ì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ìŒ“ì„ [{q:..., a:..., ...}, {q:..., a:..., ...}]
if "current_chat_log" not in st.session_state: 
    st.session_state.current_chat_log = []

# --- ì‚¬ì´ë“œë°”: ê¸°ëŠ¥ ë° ê¸°ë¡ ---
with st.sidebar:
    st.divider()
    # [ìƒˆ ëŒ€í™” ì‹œì‘] ë²„íŠ¼: í˜„ì¬ í™”ë©´ì„ ì´ˆê¸°í™”í•˜ê³  ìƒˆ ì§ˆë¬¸ì„ ë°›ì„ ì¤€ë¹„
    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘ (í™”ë©´ ì´ˆê¸°í™”)", use_container_width=True):
        # í˜„ì¬ ëŒ€í™” ë‚´ìš©ì´ ìˆë‹¤ë©´ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ì´ˆê¸°í™”
        if st.session_state.current_chat_log:
            save_session_history(current_user, st.session_state.current_chat_log)
            st.toast("ì´ì „ ëŒ€í™”ê°€ ê¸°ë¡ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        st.session_state.current_chat_log = [] # ë¦¬ìŠ¤íŠ¸ ë¹„ìš°ê¸°
        st.rerun()

    st.subheader("ğŸ—‚ï¸ ì§€ë‚œ ëŒ€í™” ê¸°ë¡")
    history_list = load_history_list(current_user)
    for idx, item in enumerate(history_list):
        if st.button(f"ğŸ“„ {item['timestamp']} | {item['title']}", key=f"hist_{idx}"):
            # ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (í˜„ì¬ í™”ë©´ì„ ë®ì–´ì”€)
            st.session_state.current_chat_log = item['dialogue']
            st.rerun()
    
    st.divider()
    if st.button("ë¡œê·¸ì•„ì›ƒ"):
        st.session_state.logged_in = False
        st.rerun()

# ==========================================
# ğŸ–¥ï¸ ë©”ì¸ íƒ­ í™”ë©´ êµ¬ì„± (ì—¬ê¸°ê°€ í•µì‹¬!)
# ==========================================

# íƒ­ì„ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘¡ë‹ˆë‹¤.
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ 1. ë‹µë³€ (Opinions)", "âš”ï¸ 2. êµì°¨ ë¶„ì„ (Cross-Analysis)", "ğŸ† 3. ìµœì¢… ê²°ë¡  (Conclusion)"])

# ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ìˆì„ ë•Œ ë Œë”ë§ ì‹œì‘
if st.session_state.current_chat_log:
    
    # [Tab 1] ì§ˆë¬¸ê³¼ ê° AIì˜ ë‹µë³€ì„ ìˆœì„œëŒ€ë¡œ ì¶œë ¥ (ëˆ„ì )
    with tab1:
        for i, log in enumerate(st.session_state.current_chat_log):
            # ì§ˆë¬¸ í‘œì‹œ (ì‘ì€ í°íŠ¸, êµµê²Œ)
            st.markdown(f"**ğŸ™‹â€â™‚ï¸ Q{i+1}. {log['q']}**") 
            
            c1, c2 = st.columns(2)
            with c1:
                st.info(f"ğŸ’ ë‹¤ì˜¨")
                st.write(log['g_resp'])
            with c2:
                st.success(f"ğŸ§  ë£¨")
                st.write(log['o_resp'])
            st.divider() # êµ¬ë¶„ì„ 

    # [Tab 2] êµì°¨ ë¶„ì„ ë‚´ìš© ìˆœì„œëŒ€ë¡œ ì¶œë ¥ (ëˆ„ì )
    with tab2:
        for i, log in enumerate(st.session_state.current_chat_log):
            st.markdown(f"**ğŸ™‹â€â™‚ï¸ Q{i+1}. {log['q']}** (ì— ëŒ€í•œ ë¶„ì„)")
            
            c1, c2 = st.columns(2)
            with c1:
                st.info("ğŸ’ ë‹¤ì˜¨ì˜ ë¹„í‰ (ë£¨ë¥¼ ë¶„ì„)")
                st.write(log['g_an'])
            with c2:
                st.success("ğŸ§  ë£¨ì˜ í‰ê°€ (ë‹¤ì˜¨ì„ ë¶„ì„)")
                st.write(log['o_an'])
            st.divider()

    # [Tab 3] ìµœì¢… ê²°ë¡  ìˆœì„œëŒ€ë¡œ ì¶œë ¥ (ëˆ„ì )
    with tab3:
        for i, log in enumerate(st.session_state.current_chat_log):
            st.markdown(f"**ğŸ™‹â€â™‚ï¸ Q{i+1}. {log['q']}** (ìµœì¢… ê²°ë¡ )")
            st.markdown(log['final_con'])
            st.divider()

# ==========================================
# âŒ¨ï¸ ì±„íŒ… ì…ë ¥ ë° ì²˜ë¦¬ (í•˜ë‹¨ ê³ ì •)
# ==========================================
user_input = st.chat_input(f"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì—”í„° ì¹˜ë©´ 1,2,3ë‹¨ê³„ ìë™ ì‹¤í–‰ | ì”ì—¬: {current_credits}íšŒ)")

if user_input:
    if current_credits > 0:
        # í¬ë ˆë”§ ì°¨ê°
        deduct_credit(current_user)
        
        # ìƒíƒœì°½ í‘œì‹œ
        with st.status("ğŸš€ 3ë‹¨ê³„ ì‹¬ì¸µ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ê°€ë™ ì¤‘...", expanded=True) as status:
            new_turn = {"q": user_input, "timestamp": datetime.now().strftime("%H:%M")}
            
            # --- STEP 1: ë‹µë³€ ---
            st.write("1ï¸âƒ£ ë‹¤ì˜¨ê³¼ ë£¨ê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤...")
            try:
                model = genai.GenerativeModel(valid_model_name)
                new_turn["g_resp"] = model.generate_content(user_input).text
            except: new_turn["g_resp"] = "Gemini ì—°ê²° ì‹¤íŒ¨"
            
            try:
                res = gpt_client.chat.completions.create(model="gpt-4o", messages=[{"role":"user","content":user_input}])
                new_turn["o_resp"] = res.choices[0].message.content
            except: new_turn["o_resp"] = "GPT ì—°ê²° ì‹¤íŒ¨"

            # --- STEP 2: êµì°¨ ë¶„ì„ ---
            st.write("2ï¸âƒ£ ì„œë¡œì˜ ë‹µë³€ì„ ê²€ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            try:
                new_turn["g_an"] = model.generate_content(f"ë‹¤ìŒì€ 'ë£¨(GPT)'ì˜ ë‹µë³€ì´ë‹¤. ë…¼ë¦¬ì  í—ˆì ì„ ë¹„íŒí•´ì¤˜:\n{new_turn['o_resp']}").text
            except: new_turn["g_an"] = "ë¶„ì„ ì‹¤íŒ¨"
            
            try:
                res = gpt_client.chat.completions.create(model="gpt-4o", messages=[{"role":"user","content":f"ë‹¤ìŒì€ 'ë‹¤ì˜¨(Gemini)'ì˜ ë‹µë³€ì´ë‹¤. ì°½ì˜ì„±ê³¼ ë…¼ë¦¬ì„±ì„ í‰ê°€í•´ì¤˜:\n{new_turn['g_resp']}"}])
                new_turn["o_an"] = res.choices[0].message.content
            except: new_turn["o_an"] = "ë¶„ì„ ì‹¤íŒ¨"
            
            # --- STEP 3: ìµœì¢… ê²°ë¡  ---
            st.write("3ï¸âƒ£ ë£¨(GPT)ê°€ ìµœì¢… ê²°ë¡ ì„ ë‚´ë¦½ë‹ˆë‹¤...")
            try:
                final_prompt = f"""
                ì§ˆë¬¸: {user_input}
                [ë‹¤ì˜¨ ë‹µë³€] {new_turn['g_resp']}
                [ë£¨ ë‹µë³€] {new_turn['o_resp']}
                [ë‹¤ì˜¨ ë¹„í‰] {new_turn['g_an']}
                [ë£¨ ë¹„í‰] {new_turn['o_an']}
                
                ìœ„ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ëª…ì¾Œí•œ ìµœì¢… ê²°ë¡ ì„ ë‚´ë ¤ë¼. 
                ì´ì „ ëŒ€í™” ë§¥ë½ì´ ìˆë‹¤ë©´ ê·¸ê²ƒë„ ê³ ë ¤í•´ë¼.
                """
                res = gpt_client.chat.completions.create(model="gpt-4o", messages=[{"role":"user","content":final_prompt}])
                new_turn["final_con"] = res.choices[0].message.content
            except: new_turn["final_con"] = "ê²°ë¡  ë„ì¶œ ì‹¤íŒ¨"

            # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ëˆ„ì )
            st.session_state.current_chat_log.append(new_turn)
            
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)
            st.rerun()
            
    else:
        st.error("ì´ìš©ê¶Œì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
