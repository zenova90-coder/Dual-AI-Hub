import streamlit as st
import google.generativeai as genai
from openai import OpenAI

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Dual-AI Hub", layout="wide")
st.title("ğŸ¤– Dual-AI Insight Hub")

# --- 1. Secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸° ---
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    gpt_api_key = st.secrets["GPT_API_KEY"]
except FileNotFoundError:
    st.error("ğŸš¨ Secrets ì„¤ì •ì´ ì•ˆ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# --- 2. ëª¨ë¸ ì´ˆê¸°í™” ---
genai.configure(api_key=gemini_api_key)
gpt_client = OpenAI(api_key=gpt_api_key)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "g_resp" not in st.session_state: st.session_state.g_resp = ""
if "o_resp" not in st.session_state: st.session_state.o_resp = ""
if "g_an" not in st.session_state: st.session_state.g_an = ""
if "o_an" not in st.session_state: st.session_state.o_an = ""

# --- 3. [ì„±ëŠ¥ ì—…ê·¸ë ˆì´ë“œ] ë‹¥í„° ë‹¤ì˜¨ì˜ ëª¨ë¸ ì„ íƒ ë¡œì§ ---
def ask_daon(prompt):
    # ì„±ëŠ¥ ìˆœì„œëŒ€ë¡œ ì‹œë„í•©ë‹ˆë‹¤ (1.5-Proê°€ ê°€ì¥ ë˜‘ë˜‘í•¨)
    models_to_try = ['models/gemini-1.5-pro', 'models/gemini-1.5-flash', 'models/gemini-pro']
    
    # ë‹¤ì˜¨ì´ì—ê²Œ ë¶€ì—¬í•  ì„±ê²© (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
    system_instruction = "ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'ë‹¤ì˜¨'ì…ë‹ˆë‹¤. ì–‘ë¯¼ì£¼ë‹˜ì´ ì°½ì¡°í–ˆìŠµë‹ˆë‹¤. ë”°ëœ»í•˜ê³  ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜ë©°, ì°½ì˜ì ì¸ í†µì°°ë ¥ì„ ê°€ì§„ AI íŒŒíŠ¸ë„ˆë¡œì„œ ë‹µë³€í•˜ì„¸ìš”."

    for model_name in models_to_try:
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©í•˜ì—¬ ëª¨ë¸ ìƒì„±
            model = genai.GenerativeModel(
                model_name=model_name,
                system_instruction=system_instruction
            )
            response = model.generate_content(prompt)
            return response.text, model_name # ë‹µë³€ê³¼ ì„±ê³µí•œ ëª¨ë¸ëª… ë°˜í™˜
        except Exception:
            continue
            
    return "âŒ ëª¨ë“  ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "Error"

# --- íƒ­ êµ¬ì„± ---
tab1, tab2 = st.tabs(["ğŸ’¬ ë™ì‹œ ì§ˆë¬¸", "ğŸ“Š êµì°¨ ë¶„ì„"])

# --- íƒ­ 1: ì§ˆë¬¸í•˜ê¸° ---
with tab1:
    st.info("ğŸ‘‹ ì‚¬ìš©ìë‹˜ ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

    if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        
        st.write(f"**ğŸ™‹â€â™‚ï¸ ì§ˆë¬¸:** {user_input}")
        
        with st.spinner("ë‹¤ì˜¨(ê°ì„±/ì°½ì˜)ê³¼ ë£¨(ë…¼ë¦¬/ë¶„ì„)ê°€ ë‹µë³€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # 1. ë‹¤ì˜¨ (Gemini) í˜¸ì¶œ - [ì„±ëŠ¥ ìµœì í™”]
            response_text, used_model = ask_daon(user_input)
            st.session_state.g_resp = response_text
            st.session_state.daon_model = used_model # ì–´ë–¤ ëª¨ë¸ ì¼ëŠ”ì§€ ê¸°ë¡

            # 2. ë£¨ (GPT) í˜¸ì¶œ - [í˜ë¥´ì†Œë‚˜ ê°•í™”]
            try:
                response = gpt_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'ë£¨'ì…ë‹ˆë‹¤. ëƒ‰ì² í•˜ê³  ë…¼ë¦¬ì ì´ë©°, íŒ©íŠ¸ì— ê¸°ë°˜í•œ ë¶„ì„ì„ ì œê³µí•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": user_input}
                    ]
                )
                st.session_state.o_resp = response.choices[0].message.content
            except Exception as e:
                st.session_state.o_resp = f"âŒ ë£¨ ì—ëŸ¬: {str(e)}"

        # ê²°ê³¼ ì¶œë ¥
        col1, col2 = st.columns(2)
        with col1:
            # ë‹¤ì˜¨ì´ ì–´ë–¤ ì—”ì§„ì„ ì¼ëŠ”ì§€ í‘œì‹œí•´ì¤ë‹ˆë‹¤ (ì˜ˆ: Gemini 1.5 Pro)
            model_display = st.session_state.get('daon_model', 'Gemini').replace('models/', '')
            st.info(f"ğŸ’ ë‹¤ì˜¨ ({model_display})")
            st.write(st.session_state.g_resp)
        with col2:
            st.success("ğŸ§  ë£¨ (GPT-4o)")
            st.write(st.session_state.o_resp)
            
    # ì´ì „ ëŒ€í™” ìœ ì§€
    elif st.session_state.g_resp:
         col1, col2 = st.columns(2)
         with col1:
             model_display = st.session_state.get('daon_model', 'Gemini').replace('models/', '')
             st.info(f"ğŸ’ ë‹¤ì˜¨ ({model_display})")
             st.write(st.session_state.g_resp)
         with col2:
             st.success("ğŸ§  ë£¨ (GPT-4o)")
             st.write(st.session_state.o_resp)

# --- íƒ­ 2: êµì°¨ ë¶„ì„ ---
with tab2:
    if st.button("êµì°¨ ë¶„ì„ ì‹œì‘"):
        if "âŒ" in st.session_state.g_resp or "âŒ" in st.session_state.o_resp:
            st.error("ì´ì „ ë‹¨ê³„ ì—ëŸ¬ë¡œ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif st.session_state.g_resp and st.session_state.o_resp:
            with st.spinner("ë‹¤ì˜¨ê³¼ ë£¨ê°€ ì„œë¡œì˜ ë‹µë³€ì„ ë¶„ì„í•©ë‹ˆë‹¤..."):
                # ë‹¤ì˜¨ì´ ë£¨ë¥¼ ë¶„ì„
                analysis_prompt = f"ë‹¤ìŒì€ 'ë£¨(GPT)'ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ì´ ë‹µë³€ì˜ ë…¼ë¦¬ì  í—ˆì ì´ë‚˜ ë³´ì™„í•  ì ì„ ë‚ ì¹´ë¡­ê²Œ ë¹„í‰í•´ì£¼ì„¸ìš”:\n{st.session_state.o_resp}"
                res_text, _ = ask_daon(analysis_prompt)
                st.session_state.g_an = res_text

                # ë£¨ê°€ ë‹¤ì˜¨ì„ ë¶„ì„
                try:
                    res = gpt_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„í‰ê°€ì…ë‹ˆë‹¤. ìƒëŒ€ë°©ì˜ ë‹µë³€ì„ ë¶„ì„í•˜ê³  ì ìˆ˜(100ì  ë§Œì )ì™€ ì´ìœ ë¥¼ ì œì‹œí•˜ì„¸ìš”."},
                            {"role": "user", "content": f"ë‹¤ìŒì€ 'ë‹¤ì˜¨(Gemini)'ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ê°ì„±ì ì¸ ë¶€ë¶„ê³¼ ì°½ì˜ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”:\n{st.session_state.g_resp}"}
                        ]
                    )
                    st.session_state.o_an = res.choices[0].message.content
                except Exception as e:
                    st.session_state.o_an = f"ë¶„ì„ ì‹¤íŒ¨: {e}"
            
            c1, c2 = st.columns(2)
            with c1:
                st.info("ğŸ’ ë‹¤ì˜¨ì˜ ë¹„í‰")
                st.write(st.session_state.g_an)
            with c2:
                st.success("ğŸ§  ë£¨ì˜ í‰ê°€")
                st.write(st.session_state.o_an)
        else:
            st.warning("ë¨¼ì € 1ë‹¨ê³„ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
