import streamlit as st

import google.generativeai as genai

from openai import OpenAI



# í˜ì´ì§€ ì„¤ì •

st.set_page_config(page_title="Dual-AI Hub", layout="wide")

st.title("ğŸ¤– Dual-AI Insight Hub")



# --- 1. Secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸° ---

try:

    gemini_api_key = st.secrets["GEMINI_API_KEY"]

    gpt_api_key = st.secrets["GPT_API_KEY"]

except FileNotFoundError:

    st.error("ğŸš¨ Secrets ì„¤ì •ì´ ì•ˆ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Streamlit Settingsë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    st.stop()



# --- 2. ëª¨ë¸ ì´ˆê¸°í™” ---

genai.configure(api_key=gemini_api_key)

gpt_client = OpenAI(api_key=gpt_api_key)



# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ê²°ë¡  ë°ì´í„° ì¶”ê°€)

if "g_resp" not in st.session_state: st.session_state.g_resp = ""

if "o_resp" not in st.session_state: st.session_state.o_resp = ""

if "g_an" not in st.session_state: st.session_state.g_an = ""

if "o_an" not in st.session_state: st.session_state.o_an = ""

if "final_con" not in st.session_state: st.session_state.final_con = "" # ìµœì¢… ê²°ë¡  ì €ì¥ìš©



# --- 3. [ë‹¥í„° ë‹¤ì˜¨] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ ì§„ë‹¨ ë° ì„ íƒ ---

def get_available_gemini_model():

    try:

        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]

        preferred_order = ['models/gemini-1.5-flash', 'models/gemini-pro', 'models/gemini-1.0-pro']

        for model in preferred_order:

            if model in available_models:

                return model

        if available_models:

            return available_models[0]

        return None

    except Exception:

        return None



valid_model_name = get_available_gemini_model()

if not valid_model_name:

    valid_model_name = "gemini-pro"



# --- íƒ­ êµ¬ì„± (3ë‹¨ê³„ ì¶”ê°€) ---

tab1, tab2, tab3 = st.tabs(["ğŸ’¬ 1. ë™ì‹œ ì§ˆë¬¸", "ğŸ“Š 2. êµì°¨ ë¶„ì„", "ğŸ† 3. ìµœì¢… ê²°ë¡ "])



# --- íƒ­ 1: ì§ˆë¬¸í•˜ê¸° ---

with tab1:

    st.info("ğŸ‘‹ ì‚¬ìš©ìë‹˜ ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

    

    if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):

        st.session_state.user_q = user_input # ì§ˆë¬¸ ë‚´ìš© ì €ì¥

        st.write(f"**ğŸ™‹â€â™‚ï¸ ì§ˆë¬¸:** {user_input}")

        

        with st.spinner("ë‹¤ì˜¨ê³¼ ë£¨ê°€ ë‹µë³€ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):

            # 1. ë‹¤ì˜¨ (Gemini)

            try:

                model = genai.GenerativeModel(valid_model_name.replace('models/', '')) 

                response = model.generate_content(user_input)

                st.session_state.g_resp = response.text

            except Exception as e:

                st.session_state.g_resp = f"âŒ ë‹¤ì˜¨ ì—ëŸ¬: {str(e)}"



            # 2. ë£¨ (GPT)

            try:

                response = gpt_client.chat.completions.create(

                    model="gpt-4o",

                    messages=[{"role": "user", "content": user_input}]

                )

                st.session_state.o_resp = response.choices[0].message.content

            except Exception as e:

                st.session_state.o_resp = f"âŒ ë£¨ ì—ëŸ¬: {str(e)}"



        col1, col2 = st.columns(2)

        with col1:

            st.info(f"ğŸ’ ë‹¤ì˜¨ ({valid_model_name})")

            st.write(st.session_state.g_resp)

        with col2:

            st.success("ğŸ§  ë£¨ (GPT-4o)")

            st.write(st.session_state.o_resp)

            

    elif st.session_state.g_resp:

         st.write(f"**ğŸ™‹â€â™‚ï¸ ì§ˆë¬¸:** {st.session_state.get('user_q', '')}")

         col1, col2 = st.columns(2)

         with col1:

             st.info(f"ğŸ’ ë‹¤ì˜¨")

             st.write(st.session_state.g_resp)

         with col2:

             st.success("ğŸ§  ë£¨ (GPT-4o)")

             st.write(st.session_state.o_resp)



# --- íƒ­ 2: êµì°¨ ë¶„ì„ ---

with tab2:

    if st.button("êµì°¨ ë¶„ì„ ì‹œì‘"):

        if not st.session_state.g_resp or not st.session_state.o_resp:

            st.warning("ë¨¼ì € 1ë‹¨ê³„ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        else:

            with st.spinner("ì„œë¡œì˜ ë…¼ë¦¬ë¥¼ ê²€ì¦í•˜ëŠ” ì¤‘..."):

                # ë‹¤ì˜¨ -> ë£¨ ë¶„ì„

                try:

                    model = genai.GenerativeModel(valid_model_name.replace('models/', ''))

                    res = model.generate_content(f"ë‹¤ìŒì€ 'ë£¨(GPT)'ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ë…¼ë¦¬ì  í—ˆì ì´ë‚˜ ë³´ì™„í•  ì ì„ ë¹„íŒì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{st.session_state.o_resp}")

                    st.session_state.g_an = res.text

                except Exception as e:

                    st.session_state.g_an = f"ë¶„ì„ ì‹¤íŒ¨: {e}"



                # ë£¨ -> ë‹¤ì˜¨ ë¶„ì„

                try:

                    res = gpt_client.chat.completions.create(

                        model="gpt-4o",

                        messages=[{"role":"user","content":f"ë‹¤ìŒì€ 'ë‹¤ì˜¨(Gemini)'ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ì°½ì˜ì„±ê³¼ ê°ì„±ì ì¸ ì¸¡ë©´, ê·¸ë¦¬ê³  ë…¼ë¦¬ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”:\n{st.session_state.g_resp}"}]

                    )

                    st.session_state.o_an = res.choices[0].message.content

                except Exception as e:

                    st.session_state.o_an = f"ë¶„ì„ ì‹¤íŒ¨: {e}"

            

            c1, c2 = st.columns(2)

            with c1:

                st.info("ğŸ’ ë‹¤ì˜¨ì˜ ë¹„í‰")

                st.write(st.session_state.g_an)

            with c2:

                st.success("ğŸ§  ë£¨ì˜ í‰ê°€")

                st.write(st.session_state.o_an)

    

    # ë¶„ì„ ê²°ê³¼ ìœ ì§€

    elif st.session_state.g_an:

        c1, c2 = st.columns(2)

        with c1:

            st.info("ğŸ’ ë‹¤ì˜¨ì˜ ë¹„í‰")

            st.write(st.session_state.g_an)

        with c2:

            st.success("ğŸ§  ë£¨ì˜ í‰ê°€")

            st.write(st.session_state.o_an)



# --- íƒ­ 3: ìµœì¢… ê²°ë¡  (New!) ---

with tab3:

    st.subheader("ğŸ† ë£¨(GPT)ê°€ ë‚´ë¦¬ëŠ” ìµœì¢… íŒê²°")

    st.caption("ì§ˆë¬¸, ë‘ AIì˜ ë‹µë³€, ê·¸ë¦¬ê³  ìƒí˜¸ ë¹„íŒ ë‚´ìš©ì„ ëª¨ë‘ ì¢…í•©í•˜ì—¬ GPT-4oê°€ ìµœì¢… ê²°ë¡ ì„ ë‚´ë¦½ë‹ˆë‹¤.")



    if st.button("ìµœì¢… ê²°ë¡  ë„ì¶œí•˜ê¸°"):

        # ë°ì´í„°ê°€ ë‹¤ ìˆëŠ”ì§€ í™•ì¸

        if not st.session_state.g_an or not st.session_state.o_an:

            st.warning("ë¨¼ì € '2. êµì°¨ ë¶„ì„' íƒ­ì—ì„œ ë¶„ì„ì„ ì™„ë£Œí•´ì•¼ ê²°ë¡ ì„ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        else:

            with st.spinner("ë£¨(GPT)ê°€ ëª¨ë“  ë…¼ì˜ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):

                try:

                    # ìµœì¢… ê²°ë¡ ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„ (ë£¨ì—ê²Œ 'ì˜ì¥' ì—­í•  ë¶€ì—¬)

                    final_prompt = f"""

                    ë„ˆëŠ” ë…¼ìŸì„ ì¤‘ì¬í•˜ê³  ìµœì¢… ê²°ë¡ ì„ ë‚´ë¦¬ëŠ” 'ìˆ˜ì„ ì˜ì¥'ì´ë‹¤.

                    ì•„ë˜ì˜ ëŒ€í™” ë‚´ìš©ì„ ëª¨ë‘ ê²€í† í•˜ê³ , ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ë„ì›€ì´ ë˜ëŠ” í•µì‹¬ ìš”ì•½ê³¼ ìµœì¢… ê²°ë¡ ì„ ì‘ì„±í•˜ë¼.



                    [ì‚¬ìš©ì ì§ˆë¬¸]

                    {st.session_state.get('user_q', '')}



                    [AI 1: ë‹¤ì˜¨(Gemini)ì˜ ì˜ê²¬]

                    {st.session_state.g_resp}



                    [AI 2: ë£¨(GPT)ì˜ ì˜ê²¬]

                    {st.session_state.o_resp}



                    [ìƒí˜¸ ë¹„íŒ 1: ë‹¤ì˜¨ì˜ ì§€ì ]

                    {st.session_state.g_an}



                    [ìƒí˜¸ ë¹„íŒ 2: ë£¨ì˜ ì§€ì ]

                    {st.session_state.o_an}



                    ---

                    [ì‘ì„± ê°€ì´ë“œ]

                    1. ë‘ ì˜ê²¬ì˜ ê³µí†µì ê³¼ ì°¨ì´ì ì„ ê°„ëµíˆ ì§šì–´ì¤„ ê²ƒ.

                    2. ìƒí˜¸ ë¹„íŒì—ì„œ ë‚˜ì˜¨ ìœ íš¨í•œ ì§€ì ì„ ë°˜ì˜í•  ê²ƒ.

                    3. ê²°ë¡ ì ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ ì´í•´í•˜ê±°ë‚˜ í–‰ë™í•˜ë©´ ì¢‹ì„ì§€ 'ìµœì¢… ì¡°ì–¸'ì„ ëª…í™•íˆ ì œì‹œí•  ê²ƒ.

                    4. í†¤ì•¤ë§¤ë„ˆ: ì „ë¬¸ì ì´ê³  ëª…ì¾Œí•˜ê²Œ.

                    """



                    # GPT-4o í˜¸ì¶œ

                    res = gpt_client.chat.completions.create(

                        model="gpt-4o",

                        messages=[{"role": "user", "content": final_prompt}]

                    )

                    st.session_state.final_con = res.choices[0].message.content

                

                except Exception as e:

                    st.error(f"ê²°ë¡  ë„ì¶œ ì‹¤íŒ¨: {e}")



    # ê²°ê³¼ ë³´ì—¬ì£¼ê¸°

    if st.session_state.final_con:

        st.markdown("---")

        st.markdown(st.session_state.final_con)

