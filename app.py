import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import time
from datetime import datetime

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Dual-AI Hub", layout="wide")
st.title("ğŸ¤– Dual-AI Insight Hub")

# --- 2. API í‚¤ ì„¤ì • ---
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    gpt_api_key = st.secrets["GPT_API_KEY"]
except KeyError:
    st.error("ğŸš¨ API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. (.streamlit/secrets.toml í™•ì¸)")
    st.stop()

genai.configure(api_key=gemini_api_key)
gpt_client = OpenAI(api_key=gpt_api_key)

# --- 3. [ìˆ˜ì •ë¨] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ íƒìƒ‰ í•¨ìˆ˜ ---
def get_working_gemini_model():
    """
    ë‚´ ê³„ì •ì—ì„œ ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ” Gemini ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.
    (404 ì—ëŸ¬ ë°©ì§€ìš©)
    """
    try:
        # í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜´
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # ìš°ë¦¬ê°€ ì„ í˜¸í•˜ëŠ” ëª¨ë¸ ìˆœì„œ (Flash -> Pro -> êµ¬ë²„ì „)
        # models/ ì ‘ë‘ì‚¬ê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° ëª¨ë‘ ëŒ€ë¹„
        preferences = [
            'models/gemini-1.5-flash', 
            'gemini-1.5-flash',
            'models/gemini-pro', 
            'gemini-pro'
        ]
        
        for pref in preferences:
            if pref in available_models:
                return pref
        
        # ì„ í˜¸ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ëª©ë¡ì˜ ì²« ë²ˆì§¸ ëª¨ë¸ ë°˜í™˜
        if available_models:
            return available_models[0]
        
        # ëª©ë¡ì¡°ì°¨ ëª» ê°€ì ¸ì˜¤ë©´ ê°€ì¥ ê¸°ë³¸ ëª¨ë¸ ì‹œë„
        return "gemini-pro"
        
    except Exception:
        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        return "gemini-pro"

# ë‚´ë¶€ì ìœ¼ë¡œ í™•ì •ëœ ëª¨ë¸ëª… (í™”ë©´ì—” ì•ˆ ë³´ì„)
VALID_MODEL_NAME = get_working_gemini_model()

# --- 4. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- 5. ì¬ì‹œë„(Retry) & ëª¨ë¸ í˜¸ì¶œ ë¡œì§ ---
def generate_with_retry(prompt, retries=3, delay=5):
    """
    429 ì—ëŸ¬(í• ë‹¹ëŸ‰ ì´ˆê³¼) ë°œìƒ ì‹œ, ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
    """
    # models/ ì ‘ë‘ì‚¬ë¥¼ ì œê±°í•´ì•¼ ì˜ ì‘ë™í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì„ ëŒ€ë¹„í•´ ë¬¸ìì—´ ì²˜ë¦¬
    clean_model_name = VALID_MODEL_NAME.replace("models/", "")
    model = genai.GenerativeModel(clean_model_name)
    
    for attempt in range(retries):
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg: # í• ë‹¹ëŸ‰ ì´ˆê³¼
                if attempt < retries - 1:
                    st.toast(f"â³ ì‚¬ìš©ëŸ‰ ì¡°ì ˆ ì¤‘... {delay}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                    time.sleep(delay)
                    continue
                else:
                    return "âŒ (ì ‘ì†ëŸ‰ í­ì£¼) ì ì‹œ í›„ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
            elif "404" in error_msg: # ëª¨ë¸ ì°¾ê¸° ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨ì´ ì•„ë‹Œ ì•ˆë‚´
                 return "âŒ ëª¨ë¸ ì„¤ì • ì˜¤ë¥˜: API í‚¤ê°€ í•´ë‹¹ ëª¨ë¸ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            else:
                return f"âŒ ì—ëŸ¬ ë°œìƒ: {error_msg}"

# --- 6. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘í•˜ê¸° (ì´ˆê¸°í™”)", use_container_width=True):
        st.session_state.chat_history = []
        st.rerun()

# --- 7. ë©”ì¸ ë¡œì§ ---
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ë‹µë³€ -> ë¶„ì„ -> ê²°ë¡  ìë™ ì§„í–‰)")

if user_input:
    with st.status("ğŸš€ AI í”„ë¡œì„¸ìŠ¤ ì§„í–‰ ì¤‘...", expanded=True) as status:
        turn_data = {
            "q": user_input,
            "timestamp": datetime.now().strftime("%H:%M"),
        }

        try:
            # [STEP 1] ë‹µë³€ ìƒì„±
            st.write("1ï¸âƒ£ ë‹¤ì˜¨(Gemini)ê³¼ ë£¨(Chat GPT)ê°€ ë‹µë³€ ì‘ì„± ì¤‘...")
            
            # ë‹¤ì˜¨ (Gemini)
            turn_data["g_resp"] = generate_with_retry(user_input)
            time.sleep(1) # ê³¼ë¶€í•˜ ë°©ì§€

            # ë£¨ (Chat GPT)
            o_res = gpt_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": user_input}]
            )
            turn_data["o_resp"] = o_res.choices[0].message.content

            # [STEP 2] êµì°¨ ë¶„ì„
            st.write("2ï¸âƒ£ ìƒí˜¸ ë¹„íŒ ë° ë¶„ì„ ì¤‘...")
            
            # ë‹¤ì˜¨ -> ë£¨ ë¹„í‰
            prompt_g = f"ë‹¤ìŒì€ Chat GPTì˜ ë‹µë³€ì´ë‹¤. ë…¼ë¦¬ì  í—ˆì ì„ ë¹„íŒí•´ì¤˜:\n{turn_data['o_resp']}"
            turn_data["g_an"] = generate_with_retry(prompt_g)
            time.sleep(1)

            # ë£¨ -> ë‹¤ì˜¨ ë¹„í‰
            prompt_o = f"ë‹¤ìŒì€ Geminiì˜ ë‹µë³€ì´ë‹¤. ì°½ì˜ì„±ê³¼ ë…¼ë¦¬ë¥¼ í‰ê°€í•´ì¤˜:\n{turn_data['g_resp']}"
            o_an = gpt_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt_o}]
            )
            turn_data["o_an"] = o_an.choices[0].message.content

            # [STEP 3] ìµœì¢… ê²°ë¡ 
            st.write("3ï¸âƒ£ ìµœì¢… ê²°ë¡  ë„ì¶œ ì¤‘...")
            final_prompt = f"""
            ì§ˆë¬¸: {user_input}
            [Gemini ë‹µë³€]: {turn_data['g_resp']}
            [Chat GPT ë‹µë³€]: {turn_data['o_resp']}
            [Gemini ë¹„í‰]: {turn_data['g_an']}
            [Chat GPT ë¹„í‰]: {turn_data['o_an']}
            
            ìœ„ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìë¥¼ ìœ„í•œ ëª…í™•í•œ ìµœì¢… ê²°ë¡ ì„ ë‚´ë ¤ì¤˜.
            """
            final_res = gpt_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": final_prompt}]
            )
            turn_data["final_con"] = final_res.choices[0].message.content

            # ì €ì¥
            st.session_state.chat_history.append(turn_data)
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

        except Exception as e:
            st.error(f"ì‹œìŠ¤í…œ ì—ëŸ¬: {e}")

# --- 8. ê²°ê³¼ ì¶œë ¥ ---
if st.session_state.chat_history:
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ ì˜ê²¬ ëŒ€ë¦½", "âš”ï¸ êµì°¨ ê²€ì¦", "ğŸ† ìµœì¢… ê²°ë¡ "])
    
    for i, chat in enumerate(st.session_state.chat_history):
        idx = i + 1
        with tab1:
            st.markdown(f"#### Q{idx}. {chat['q']}")
            c1, c2 = st.columns(2)
            with c1: 
                st.info("ğŸ’ ë‹¤ì˜¨ (Gemini)") 
                st.write(chat['g_resp'])
            with c2: 
                st.success("ğŸ§  ë£¨ (Chat GPT)") 
                st.write(chat['o_resp'])
            st.divider()
        with tab2:
            st.markdown(f"#### Q{idx} ë¶„ì„")
            c1, c2 = st.columns(2)
            with c1: 
                st.info("ğŸ’ ë‹¤ì˜¨ (Gemini)ì˜ ë¹„í‰")
                st.write(chat['g_an'])
            with c2: 
                st.success("ğŸ§  ë£¨ (Chat GPT)ì˜ í‰ê°€")
                st.write(chat['o_an'])
            st.divider()
        with tab3:
            st.markdown(f"#### ğŸ† Q{idx} ê²°ë¡ ")
            st.write(chat['final_con'])
            st.divider()
