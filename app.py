import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import time
from datetime import datetime

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Dual-AI Hub", layout="wide")
st.title("ğŸ¤– Dual-AI Insight Hub")

# --- 2. API í‚¤ ì„¤ì • ---
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    gpt_api_key = st.secrets["GPT_API_KEY"]
except KeyError:
    st.error("ğŸš¨ API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. (.streamlit/secrets.toml í™•ì¸)")
    st.stop()

genai.configure(api_key=gemini_api_key)
gpt_client = OpenAI(api_key=gpt_api_key)

# ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•  ëª¨ë¸ (ì•ˆì •ì„± ìµœìš°ì„ , ì‚¬ìš©ìì—ê²ŒëŠ” ì•ˆ ë³´ì„)
INTERNAL_MODEL_NAME = "gemini-1.5-flash"

# --- 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- 4. ì¬ì‹œë„(Retry) ë¡œì§ í•¨ìˆ˜ ---
def generate_with_retry(model_name, prompt, retries=3, delay=5):
    """
    429 ì—ëŸ¬(í• ë‹¹ëŸ‰ ì´ˆê³¼) ë°œìƒ ì‹œ, ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„í•˜ëŠ” ì•ˆì •í™” í•¨ìˆ˜
    """
    model = genai.GenerativeModel(model_name)
    
    for attempt in range(retries):
        try:
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e):
                if attempt < retries - 1:
                    st.toast(f"â³ ì‚¬ìš©ëŸ‰ ì¡°ì ˆ ì¤‘... {delay}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                    time.sleep(delay)
                    continue
                else:
                    return "âŒ (ì ‘ì†ëŸ‰ í­ì£¼) ì ì‹œ í›„ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
            else:
                return f"âŒ ì—ëŸ¬ ë°œìƒ: {str(e)}"

# --- 5. ì‚¬ì´ë“œë°” (ì‹¬í”Œ ëª¨ë“œ) ---
with st.sidebar:
    # ë²„ì „ ì •ë³´ ì—†ì´ ê¹”ë”í•˜ê²Œ ì´ˆê¸°í™” ë²„íŠ¼ë§Œ ìœ ì§€
    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘í•˜ê¸° (ì´ˆê¸°í™”)", use_container_width=True):
        st.session_state.chat_history = []
        st.rerun()

# --- 6. ë©”ì¸ ë¡œì§ ---
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ë‹µë³€ -> ë¶„ì„ -> ê²°ë¡  ìë™ ì§„í–‰)")

if user_input:
    with st.status("ğŸš€ AI í”„ë¡œì„¸ìŠ¤ ì§„í–‰ ì¤‘...", expanded=True) as status:
        turn_data = {
            "q": user_input,
            "timestamp": datetime.now().strftime("%H:%M"),
        }

        try:
            # [STEP 1] ë‹µë³€ ìƒì„±
            st.write("1ï¸âƒ£ ë‹¤ì˜¨(Gemini)ê³¼ ë£¨(Chat GPT)ê°€ ë‹µë³€ ì‘ì„± ì¤‘...")
            
            # ë‹¤ì˜¨ (Gemini)
            turn_data["g_resp"] = generate_with_retry(INTERNAL_MODEL_NAME, user_input)
            time.sleep(1) # ê³¼ë¶€í•˜ ë°©ì§€ ì¿¨íƒ€ì„

            # ë£¨ (Chat GPT)
            o_res = gpt_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": user_input}]
            )
            turn_data["o_resp"] = o_res.choices[0].message.content

            # [STEP 2] êµì°¨ ë¶„ì„
            st.write("2ï¸âƒ£ ìƒí˜¸ ë¹„íŒ ë° ë¶„ì„ ì¤‘...")
            
            # ë‹¤ì˜¨ -> ë£¨ ë¹„í‰
            prompt_g = f"ë‹¤ìŒì€ Chat GPTì˜ ë‹µë³€ì´ë‹¤. ë…¼ë¦¬ì  í—ˆì ì„ ë¹„íŒí•´ì¤˜:\n{turn_data['o_resp']}"
            turn_data["g_an"] = generate_with_retry(INTERNAL_MODEL_NAME, prompt_g)
            time.sleep(1)

            # ë£¨ -> ë‹¤ì˜¨ ë¹„í‰
            prompt_o = f"ë‹¤ìŒì€ Geminiì˜ ë‹µë³€ì´ë‹¤. ì°½ì˜ì„±ê³¼ ë…¼ë¦¬ë¥¼ í‰ê°€í•´ì¤˜:\n{turn_data['g_resp']}"
            o_an = gpt_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt_o}]
            )
            turn_data["o_an"] = o_an.choices[0].message.content

            # [STEP 3] ìµœì¢… ê²°ë¡ 
            st.write("3ï¸âƒ£ ìµœì¢… ê²°ë¡  ë„ì¶œ ì¤‘...")
            final_prompt = f"""
            ì§ˆë¬¸: {user_input}
            [Gemini ë‹µë³€]: {turn_data['g_resp']}
            [Chat GPT ë‹µë³€]: {turn_data['o_resp']}
            [Gemini ë¹„í‰]: {turn_data['g_an']}
            [Chat GPT ë¹„í‰]: {turn_data['o_an']}
            
            ìœ„ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìë¥¼ ìœ„í•œ ëª…í™•í•œ ìµœì¢… ê²°ë¡ ì„ ë‚´ë ¤ì¤˜.
            """
            final_res = gpt_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": final_prompt}]
            )
            turn_data["final_con"] = final_res.choices[0].message.content

            # ì €ì¥
            st.session_state.chat_history.append(turn_data)
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

        except Exception as e:
            st.error(f"ì‹œìŠ¤í…œ ì—ëŸ¬: {e}")

# --- 7. ê²°ê³¼ ì¶œë ¥ (ëˆ„ì í˜• íƒ­) ---
if st.session_state.chat_history:
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ ì˜ê²¬ ëŒ€ë¦½", "âš”ï¸ êµì°¨ ê²€ì¦", "ğŸ† ìµœì¢… ê²°ë¡ "])
    
    # ìµœì‹  ëŒ€í™”ê°€ ì•„ë˜ì— ìŒ“ì„
    for i, chat in enumerate(st.session_state.chat_history):
        idx = i + 1
        with tab1:
            st.markdown(f"#### Q{idx}. {chat['q']}")
            c1, c2 = st.columns(2)
            with c1: 
                st.info("ğŸ’ ë‹¤ì˜¨ (Gemini)") 
                st.write(chat['g_resp'])
            with c2: 
                st.success("ğŸ§  ë£¨ (Chat GPT)") 
                st.write(chat['o_resp'])
            st.divider()
        with tab2:
            st.markdown(f"#### Q{idx} ë¶„ì„")
            c1, c2 = st.columns(2)
            with c1: 
                st.info("ğŸ’ ë‹¤ì˜¨ (Gemini)ì˜ ë¹„í‰")
                st.write(chat['g_an'])
            with c2: 
                st.success("ğŸ§  ë£¨ (Chat GPT)ì˜ í‰ê°€")
                st.write(chat['o_an'])
            st.divider()
        with tab3:
            st.markdown(f"#### ğŸ† Q{idx} ê²°ë¡ ")
            st.write(chat['final_con'])
            st.divider()
