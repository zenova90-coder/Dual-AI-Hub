import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import json
import os
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Dual-AI Hub", layout="wide")
st.title("ğŸ¤– Dual-AI Insight Hub")

# --- 1. íŒŒì¼ ê¸°ë°˜ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ---
HISTORY_FILE = "chat_history.json"

def load_history():
    if not os.path.exists(HISTORY_FILE): return []
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data if isinstance(data, list) else []
    except: return []

def save_session_history(session_data):
    if not session_data: return
    history = load_history()
    first_q = session_data[0].get('q', 'ì œëª© ì—†ìŒ')
    record = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "title": first_q[:15] + "...", 
        "dialogue": session_data
    }
    history.insert(0, record) 
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=4)

def delete_history():
    if os.path.exists(HISTORY_FILE): os.remove(HISTORY_FILE)

# --- 2. API í‚¤ ì„¤ì • ---
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
    gpt_api_key = st.secrets["GPT_API_KEY"]
    genai.configure(api_key=gemini_api_key)
    gpt_client = OpenAI(api_key=gpt_api_key)
except:
    st.error("ğŸš¨ API í‚¤ ì„¤ì • ì˜¤ë¥˜")
    st.stop()

# --- 3. ì„¸ì…˜ ì´ˆê¸°í™” ---
if "current_chat_log" not in st.session_state: 
    st.session_state.current_chat_log = []

# --- 4. ëª¨ë¸ ì„¤ì • (ì•ˆì •ì ì¸ ë²„ì „ìœ¼ë¡œ ê³ ì •) ---
def get_gemini_model():
    # 404 ì—ëŸ¬ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ê°€ì¥ ì•ˆì •ì ì¸ 'gemini-pro'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    return 'gemini-pro'

valid_model_name = get_gemini_model()

# --- 5. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("ğŸ—‚ï¸ ëŒ€í™” ê¸°ë¡")
    if st.button("â• ìƒˆ ëŒ€í™” ì‹œì‘ (í™”ë©´ ì´ˆê¸°í™”)", use_container_width=True):
        if st.session_state.current_chat_log:
            save_session_history(st.session_state.current_chat_log)
        st.session_state.current_chat_log = [] 
        st.rerun()

    st.divider()
    history_data = load_history()
    if not history_data: st.caption("ê¸°ë¡ ì—†ìŒ")
    else:
        for idx, item in enumerate(history_data):
            ts = item.get('timestamp', '')
            ti = item.get('title', 'ì œëª© ì—†ìŒ')
            if st.button(f"{ts} | {ti}", key=f"hist_{idx}", use_container_width=True):
                st.session_state.current_chat_log = item.get('dialogue', [])
                st.rerun()

    st.divider()
    if st.button("ğŸ—‘ï¸ ëª¨ë“  ê¸°ë¡ ì‚­ì œ"):
        delete_history()
        st.session_state.current_chat_log = []
        st.rerun()

# --- 6. ë©”ì¸ í™”ë©´ (íƒ­) ---
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ 1. ë‹µë³€", "âš”ï¸ 2. êµì°¨ ë¶„ì„", "ğŸ† 3. ìµœì¢… ê²°ë¡ "])

if st.session_state.current_chat_log:
    with tab1:
        for i, turn in enumerate(st.session_state.current_chat_log):
            st.markdown(f"**Q{i+1}. {turn['q']}**") 
            c1, c2 = st.columns(2)
            # [ìš”ì²­ ë°˜ì˜] ì´ë¦„í‘œ ìˆ˜ì •
            c1.info("ğŸ’ ë‹¤ì˜¨ (Gemini)"); c1.write(turn.get('g_resp', ''))
            c2.success("ğŸ§  ë£¨ (Chat GPT)"); c2.write(turn.get('o_resp', ''))
            st.divider()
    with tab2:
        for i, turn in enumerate(st.session_state.current_chat_log):
            st.markdown(f"**Q{i+1} ë¶„ì„**")
            c1, c2 = st.columns(2)
            c1.info("ğŸ’ ë‹¤ì˜¨ì˜ ë¹„í‰"); c1.write(turn.get('g_an', ''))
            c2.success("ğŸ§  ë£¨ì˜ í‰ê°€"); c2.write(turn.get('o_an', ''))
            st.divider()
    with tab3:
        for i, turn in enumerate(st.session_state.current_chat_log):
            st.markdown(f"**Q{i+1} ê²°ë¡ **")
            st.markdown(turn.get('final_con', ''))
            st.divider()
else:
    with tab1: st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ëŒ€í™”ê°€ ì‹œì‘ë©ë‹ˆë‹¤.")

# --- 7. ì‹¤í–‰ ë¡œì§ ---
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

if user_input:
    with st.status("ğŸš€ ë‹¤ì˜¨ê³¼ ë£¨ê°€ ë¶„ì„ ì¤‘...", expanded=True) as status:
        new_turn = {"q": user_input, "timestamp": datetime.now().strftime("%H:%M")}

        # STEP 1: ë‹µë³€
        st.write("1ï¸âƒ£ ë‹µë³€ ì‘ì„± ì¤‘...")
        try:
            model = genai.GenerativeModel(valid_model_name)
            new_turn["g_resp"] = model.generate_content(user_input).text
        except Exception as e: new_turn["g_resp"] = f"Gemini ì˜¤ë¥˜: {e}"

        try:
            o_res = gpt_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": user_input}])
            new_turn["o_resp"] = o_res.choices[0].message.content
        except Exception as e: new_turn["o_resp"] = f"GPT ì˜¤ë¥˜: {e}"

        # STEP 2: ë¶„ì„ (ì•ˆì „ ì„¤ì • í•´ì œ ìœ ì§€)
        st.write("2ï¸âƒ£ êµì°¨ ë¶„ì„ ì¤‘...")
        
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]

        try:
            prompt = f"ë‹¤ìŒì€ 'ë£¨(GPT)'ì˜ ë‹µë³€ì´ë‹¤. ë…¼ë¦¬ì  í—ˆì ì„ ë‚ ì¹´ë¡­ê²Œ ë¹„íŒí•´ì¤˜:\n---\n{new_turn['o_resp']}"
            g_an = model.generate_content(prompt, safety_settings=safety_settings)
            new_turn["g_an"] = g_an.text
        except Exception as e: new_turn["g_an"] = f"ë¶„ì„ ì‹¤íŒ¨: {e}"

        try:
            prompt = f"ë‹¤ìŒì€ 'ë‹¤ì˜¨(Gemini)'ì˜ ë‹µë³€ì´ë‹¤. í‰ê°€í•´ì¤˜:\n---\n{new_turn['g_resp']}"
            o_an = gpt_client.chat.completions.create(model="gpt-4o", messages=[{"role":"user","content":prompt}])
            new_turn["o_an"] = o_an.choices[0].message.content
        except: new_turn["o_an"] = "ë¶„ì„ ì‹¤íŒ¨"

        # STEP 3: ê²°ë¡ 
        st.write("3ï¸âƒ£ ê²°ë¡  ë„ì¶œ ì¤‘...")
        try:
            final_prompt = f"ì§ˆë¬¸: {new_turn['q']}\në‹µë³€1: {new_turn['g_resp']}\në‹µë³€2: {new_turn['o_resp']}\në¹„í‰1: {new_turn['g_an']}\në¹„í‰2: {new_turn['o_an']}\nì¢…í•© ê²°ë¡ ì„ ë‚´ë ¤ë¼."
            final_res = gpt_client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": final_prompt}])
            new_turn["final_con"] = final_res.choices[0].message.content
        except: new_turn["final_con"] = "ê²°ë¡  ì‹¤íŒ¨"

        st.session_state.current_chat_log.append(new_turn)
        status.update(label="âœ… ì™„ë£Œ!", state="complete", expanded=False)
        st.rerun()
